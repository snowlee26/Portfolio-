{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Default Rate Analysis and Prediction: \n",
    "# Part 2, Build Default Payment Prediction Model\n",
    "\n",
    "## Background\n",
    "### Problem\n",
    "\n",
    "Over the past year or so Credit One has seen an increase in the number of customers who have defaulted on loans \n",
    "they have secured from various partners. Credit One, as their credit scoring service, could risk losing business \n",
    "if the problem is not solved right away. They have enlisted the help of our Data Science team to design and \n",
    "implement a creative, empirically sound solution. \n",
    "\n",
    "### Goals\n",
    "\n",
    "* Examining current customer demographics.\n",
    "* Understand what traits relate to customers’ current credit obligations.\n",
    "* Identify which attributes relate significantly to customer default rates.\n",
    "  * Here is the [Exploratory Data Analysis](https://github.com/snowlee26/Portfolio-/blob/master/Formal%20EDA%20.ipynb) for the first three goals. \n",
    "* Build a predictive model to better classify potential “at risk” customers.\n",
    "\n",
    "### Dataset Information\n",
    "\n",
    "* This data source aimed at the case of customers default payments in Taiwan.\n",
    "* Dataset contains 30,000 customer defualt information. \n",
    "* Attributes include:\n",
    "     * Amount of the given credit, Gender, Education\n",
    "     * Marital Status, Age, History of past payments\n",
    "     * Amount of bill statement, Amount of previous payment \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Evaluating Process\n",
    "\n",
    "### Pre-processing and Feature Engineering\n",
    "[Exploratory Data Analysis](https://github.com/snowlee26/Portfolio-/blob/master/Formal%20EDA%20.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy, pandas, scipy, math, matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The dataset we upload here has been pre-processed from the previous EDA section.\n",
    "* We used df.info() to make sure that all the attributes are in the numerical form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1    0      2      2     -1     -1   \n",
       "1     120000    2          2         2    0     -1      2      0      0   \n",
       "2      90000    2          2         2    0      0      0      0      0   \n",
       "3      50000    2          2         1    1      0      0      0      0   \n",
       "4      50000    1          2         1    2     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "3      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "4      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData = pd.read_csv('new_credit.csv')\n",
    "rawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 24 columns):\n",
      "LIMIT_BAL                     30000 non-null int64\n",
      "SEX                           30000 non-null int64\n",
      "EDUCATION                     30000 non-null int64\n",
      "MARRIAGE                      30000 non-null int64\n",
      "AGE                           30000 non-null int64\n",
      "PAY_0                         30000 non-null int64\n",
      "PAY_2                         30000 non-null int64\n",
      "PAY_3                         30000 non-null int64\n",
      "PAY_4                         30000 non-null int64\n",
      "PAY_5                         30000 non-null int64\n",
      "PAY_6                         30000 non-null int64\n",
      "BILL_AMT1                     30000 non-null int64\n",
      "BILL_AMT2                     30000 non-null int64\n",
      "BILL_AMT3                     30000 non-null int64\n",
      "BILL_AMT4                     30000 non-null int64\n",
      "BILL_AMT5                     30000 non-null int64\n",
      "BILL_AMT6                     30000 non-null int64\n",
      "PAY_AMT1                      30000 non-null int64\n",
      "PAY_AMT2                      30000 non-null int64\n",
      "PAY_AMT3                      30000 non-null int64\n",
      "PAY_AMT4                      30000 non-null int64\n",
      "PAY_AMT5                      30000 non-null int64\n",
      "PAY_AMT6                      30000 non-null int64\n",
      "default payment next month    30000 non-null int64\n",
      "dtypes: int64(24)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "rawData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building models \n",
    "**We were asked to predict if certain customer will be default for the next month payment. The result will be either \n",
    "Yes or No, so this is a classification problem, we will be using classification classifiers to build the models.**\n",
    "\n",
    "* All the features besides \"default payment next month\" were selected as independent variables.\n",
    "* \"default payment next month\" was selected as the dependent variable, the one we need to predict.\n",
    "* We used train_test_split() function to randomly split training and testing datasets.\n",
    "* After spliting the datasets, we used four different classification classifiers to build four different models.\n",
    "  * Logistic Regression\n",
    "  * Random Forest\n",
    "  * Gradient Boosting\n",
    "  * Supportive Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2682</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13559</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49291</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35835</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1    0      2      2     -1     -1   \n",
       "1     120000    2          2         2    0     -1      2      0      0   \n",
       "2      90000    2          2         2    0      0      0      0      0   \n",
       "3      50000    2          2         1    1      0      0      0      0   \n",
       "4      50000    1          2         1    2     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0     -2  ...        689          0          0          0         0       689   \n",
       "1      0  ...       2682       3272       3455       3261         0      1000   \n",
       "2      0  ...      13559      14331      14948      15549      1518      1500   \n",
       "3      0  ...      49291      28314      28959      29547      2000      2019   \n",
       "4      0  ...      35835      20940      19146      19131      2000     36681   \n",
       "\n",
       "   PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "0         0         0         0         0  \n",
       "1      1000      1000         0      2000  \n",
       "2      1000      1000      1000      5000  \n",
       "3      1200      1100      1069      1000  \n",
       "4     10000      9000       689       679  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify features\n",
    "features = rawData.iloc[:,0:23]\n",
    "print('Summary of features')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify dependent variable\n",
    "depVar = rawData['default payment next month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# establish train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, depVar, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22500, 23), (7500, 23))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the shape function to double check that the split was made as needed:\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the classifier\n",
    "modelLR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16478800773620605"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model and time it\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "modelLR.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7783555555555556"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the accuracy \n",
    "modelLR.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the classifier\n",
    "modelRF = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.912303924560547"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model and time it\n",
    "t0 = time.time()\n",
    "modelRF.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968444444444444"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the accuracy\n",
    "modelRF.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the classifier\n",
    "GB = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8301010131835938"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model and time it\n",
    "t0 = time.time()\n",
    "modelGB = GB.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268888888888889"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the accuracy\n",
    "modelGB.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the classifier\n",
    "modelSVM = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.1027672290802"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model and time it\n",
    "t0 = time.time()\n",
    "modelSVM.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904444444444445"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the accuracy\n",
    "modelSVM.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Both Random Forest and SVM models have accuracy above 0.99, it is obvious that those two models are overfitting.\n",
    "We are going to use Cross Validation to solve this problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cross Validation\n",
    "\n",
    "Cross-validation is a resampling procedure. It splits a given data sample into numbers of groups. Each group is called\n",
    "a fold, total k(any number) folds. We chose a training set of the size of one fold, train our model on that partition, \n",
    "all the folds will be examined. Then we evaluate the results on the remaining test data. The final results/scores are \n",
    "averaged out.\n",
    "This could avoid overfitting problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7784    , 0.7784    , 0.77826667])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 3 fold validation\n",
    "cross_val_score(LogisticRegression(random_state=0), X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81453333, 0.81186667, 0.81373333])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators=25, random_state=0), X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82442341, 0.82426667, 0.81490865])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_cv = GradientBoostingClassifier(n_estimators=25, random_state=0)\n",
    "scores = cross_val_score(GB_cv, X_train, y_train, cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78053333, 0.77933333, 0.77813333])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(random_state=0), X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cross Validation sucessfully avoided overfitting problem. \n",
    "* Model with the highest accuracy is Gradient Boosting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and Evaluate the Models\n",
    "\n",
    "* For Logestic Regression and Gradient Boosting. We will use the models built from train_test_split() on the testing\n",
    "dataset, since the accuracies are almost the same with the ones built from cross validation, at the same time they\n",
    "took much less time to run. \n",
    "* For Random Forest and SVM, will use the models built from cross validation, since the ones from train_test_split()\n",
    "are overfitting. \n",
    "* For evaluating, We will use confusion matrix to acculate the accuracy and we will also print out classification report\n",
    "for each model include precision, recall, f1-score and support. \n",
    "  * Precision – Accuracy of positive predictions. It indicates among all the positive predictions, how many are real positive.\n",
    "  * Recall – Fraction of positives that were correctly identified. It indicates among all the positive instances, how many did you predict right. \n",
    "  * F1 score – It takes both precision and recall into consideration. The best score is 1 and the worst is 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logestic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5850,    0],\n",
       "       [1650,    0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predictions_LR = modelLR.predict(X_test)\n",
    "confusion_matrix(y_test, predictions_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      5850\n",
      "           1       0.00      0.00      0.00      1650\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      7500\n",
      "   macro avg       0.39      0.50      0.44      7500\n",
      "weighted avg       0.61      0.78      0.68      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "reportLR = classification_report(y_test, predictions_LR)\n",
    "print(reportLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5451,  399],\n",
       "       [1031,  619]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "RF_cv = RandomForestClassifier(n_estimators=25, random_state=0)\n",
    "modelRF_cv = RF_cv.fit(X_train, y_train)\n",
    "predictions_RF_cv = cross_val_predict(modelRF_cv, X_test, y_test, cv=3)\n",
    "confusion_matrix(y_test, predictions_RF_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      5850\n",
      "           1       0.61      0.38      0.46      1650\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      7500\n",
      "   macro avg       0.72      0.65      0.67      7500\n",
      "weighted avg       0.79      0.81      0.79      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reportRF = classification_report(y_test, predictions_RF_cv)\n",
    "print(reportRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5554,  296],\n",
       "       [1048,  602]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_GB = modelGB.predict(X_test)\n",
    "confusion_matrix(y_test, predictions_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      5850\n",
      "           1       0.67      0.36      0.47      1650\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      7500\n",
      "   macro avg       0.76      0.66      0.68      7500\n",
      "weighted avg       0.80      0.82      0.80      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reportGB = classification_report(y_test, predictions_GB)\n",
    "print(reportGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5823,   27],\n",
       "       [1607,   43]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_cv = SVC()\n",
    "modelSVM_cv = SVM_cv.fit(X_train, y_train)\n",
    "predictions_SVM_cv = cross_val_predict(modelSVM_cv, X_test, y_test, cv=3)\n",
    "confusion_matrix(y_test, predictions_SVM_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      5850\n",
      "           1       0.61      0.03      0.05      1650\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      7500\n",
      "   macro avg       0.70      0.51      0.46      7500\n",
      "weighted avg       0.75      0.78      0.70      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reportSVM = classification_report(y_test, predictions_SVM_cv)\n",
    "print(reportSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of Model Performances by Graphs**\n",
    "\n",
    "* Time taken for each model to run(using train_test_split() function).\n",
    "![](TimeTaken.png)\n",
    "\n",
    "* Accuracy and F1 score of each model. \n",
    "\n",
    "|Accuracy|F1 Score|\n",
    "|--------|--------|\n",
    "|![](Accuracy.png)|![](F1.png)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Model Selection - Gradient Boosting**\n",
    "\n",
    "After comparing all the models we have built: Logestic Regression, Random Forest, Gradient Boosting and SVM. The \n",
    "optimal model we have chosen is Gradient Boosting, based on the F1 Score and time taken. \n",
    "\n",
    "Logestic Regression and SVM have relativly low accuracy and F1 score. Especially for Logestic Regression, both precision\n",
    "and recall for default class are 0. This could lead to very bad prediction, the model doesn't have the ability to detect\n",
    "default customers for the next month. \n",
    "\n",
    "Random Forest and Gradient Boosting have very similar accuracy and F1 score. But Gradient Boosting takes almost half of \n",
    "the time to build than Random Forest. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggestions to Credit One\n",
    "\n",
    "* Deploy the final model to different platforms: computer, smartphone and tablet etc.  \n",
    "* Use the deployed model as a reference to see if the client is more likely to be default or not. \n",
    "* Auto-approval for loans below certain amount using the model to improve the efficiency.  \n",
    "* Maintain the model regularly to ensure its best performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
